{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Category - Machine Hack v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "THql6reHg-4T",
        "ZLWOUH7dS4jE",
        "CLGHMgTK66wF",
        "r-ixnTvp69gz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashayghiya/Hackathons/blob/master/News_Category_Machine_Hack_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THql6reHg-4T",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4CrfZm-yE6V",
        "colab_type": "code",
        "outputId": "03d699f6-7ba1-4826-982f-e99ac4081130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import gensim\n",
        "from gensim import corpora, models\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Others\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(2019)\n",
        "\n",
        "# Disable Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9Gz45Sybhw",
        "colab_type": "code",
        "outputId": "315767c9-9166-43e8-dfd8-ecb6cb1a1f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_excel(r'Data_Train.xlsx')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  SECTION\n",
              "0  But the most painful was the huge reversal in ...        3\n",
              "1  How formidable is the opposition alliance amon...        0\n",
              "2  Most Asian currencies were trading lower today...        3\n",
              "3  If you want to answer any question, click on ‘...        1\n",
              "4  In global markets, gold prices edged up today ...        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f79tc6WMypYj",
        "colab_type": "code",
        "outputId": "9db1aa8a-f1d8-47ee-b9ab-4ced171884c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df['SECTION'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2772\n",
              "2    1924\n",
              "0    1686\n",
              "3    1246\n",
              "Name: SECTION, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgkDxmw5_hsg",
        "colab_type": "code",
        "outputId": "fab300b5-3d8b-44d8-e46b-a064ab67d570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "num_words = [len(s.split()) for s in df['STORY']]\n",
        "print(r'number of words per sample: {}'.format(np.mean(num_words)))\n",
        "print(r'number of samples: {}'.format(len(num_words)))\n",
        "print(r'ratio: {}'.format(len(num_words)/np.mean(num_words)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of words per sample: 107.58927635028842\n",
            "number of samples: 7628\n",
            "ratio: 70.89925928272638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0R26-yAx_6kG",
        "outputId": "2a196dc3-9f3b-4041-f6c3-7c75bde8e36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "sns.distplot([len(s) for s in df['STORY']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f850db978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X10XHd95/H3d2ak0bNky7Li+El2\nbCdReAjEJEBpoKSQwHbx7jnh4MDS0IZm24ZDW3ZPm5xy6Da72UOW0wa6DdBsSUk5SZ0QHurSQAoJ\nFCiNEwVCiO3YFn5+iCQ/6MGSRhrNfPePueNMlNFoZI3mzsif1zk6vvOb3/3d77XH89Xv/n73d83d\nERERmUkk7ABERKSyKVGIiEhBShQiIlKQEoWIiBSkRCEiIgUpUYiISEFKFCIiUpAShYiIFKREISIi\nBcXCDqAUli1b5l1dXWGHISJSVZ599tmT7t4xW71FkSi6urro6ekJOwwRkapiZoeKqadLTyIiUpAS\nhYiIFKREISIiBSlRiIhIQUoUIiJSkBKFiIgUpEQhIiIFKVGIiEhBShQiIlLQorgzO0wP7Tj8qrIP\nXrMmhEhERBaGehQiIlJQUYnCzG4wsz1m1mtmt+d5P25mDwfv7zCzrpz37gjK95jZ9Tnl95tZv5m9\nMK2tz5jZi2b2vJl9w8zazv/0RERkvmZNFGYWBe4F3gN0AzeZWfe0arcAZ9x9A3APcHewbzewFbgC\nuAH4fNAewJeDsum+C7zG3V8H7AXumOM5iYhICRXTo7ga6HX3/e4+CWwDtkyrswV4INh+FLjOzCwo\n3+buE+5+AOgN2sPdfwicnn4wd/8Xd58KXj4FrJrjOYmISAkVkyhWAkdyXh8NyvLWCb7kh4D2Ivct\n5LeBb8+hvoiIlFjFDmab2Z8CU8CDM7x/q5n1mFnPwMBAeYObxbd/cYK+4UTYYYiIlEQxieIYsDrn\n9aqgLG8dM4sBrcCpIvd9FTP7CPAbwIfc3fPVcff73H2zu2/u6Jj1AU1lc+T0GL/34E/5n9/aFXYo\nIiIlUUyieAbYaGbrzKyWzOD09ml1tgM3B9s3Ak8GX/Dbga3BrKh1wEbg6UIHM7MbgD8G3ufuY8Wf\nSmX4/p5+AL79wkscGxwPORoRkfmbNVEEYw4fAx4HdgOPuPtOM7vTzN4XVPsS0G5mvcAngNuDfXcC\njwC7gO8At7l7CsDM/gH4d+BSMztqZrcEbf010Ax818yeM7MvluhcF9zxwXFefGmErW/KdKL+/icH\nww1IRKQEiroz290fAx6bVvapnO0E8P4Z9r0LuCtP+U0z1N9QTEyV6Ad7B4jHItzx3ssZSUzx0NOH\n+fh1G2mM6wZ4Eale+gYrkf7hBDuPDfH2Szv45+dPsHpJPSOJKf7ka8/z1kuWAVraQ0SqU8XOeqo2\nu08M43AuKaxpb2T1knp2HHjVrSIiIlVFiaJE+kcmaK2voSnnMtMVF7cyMDLBSCIZYmQiIvOjRFEi\n/SMTLG+Ov6JsbXsDAIdPV93kLRGRc5QoSiDtTv9I4lWJYmVbPbGIceiUEoWIVC8lihIYHEuSTDnL\nW+peUR6LRli5pJ5Dp0ZDikxEZP6UKEqgfySzXMf0HgXA2qWNHB9MkEylyx2WiEhJKFGUQP/wBADL\nm+te9d7a9gZS7hw9o7u0RaQ66T6KIuV75GlW/8gEzXUx6mujr3pv7dLMgLYuP4lItVKPogTyDWRn\nNcRjdDTFNaAtIlVLiWKe3D2YGvvqy05Za9sbOHx6jHQ670K4IiIVTYlinobGk0xOpVnekr9HAZlE\nMZ5M8cuBs2WMTESkNJQo5ql/ZOaB7Ky1SxsB6Dl0piwxiYiUkhLFPL2cKGbuUbQ31dJYG6XnoBKF\niFQfJYp56h9O0FgbLbiUuJmxtr2RZw9pgUARqT5KFPPUPzLxqjuy81nb3sDBU2MMBD0QEZFqoUQx\nD+7OwMgEHU0zX3bKyt5PoV6FiFQbJYp5GJ1MMZ5M0VFgfCLr4rZ6amMRjVOISNVRopiHk8FlpGVF\n9Chi0QivX9WqmU8iUnWUKObh5NlMoiimRwFw1dql7Dw+RCKZWsiwRERKSoliHgbOThCLGG0NNUXV\n37x2CcmU8/MjgwscmYhI6ShRzMPJkQmWNtYSMSuq/lVrlwC68U5EqosSxTwMnJ0s+rITwJLGWjYs\nb2LHAc18EpHqoURxnlJp5/ToRFED2bnetmEZTx84pXEKEakaShTn6czoJGmnqHsocr19UweJZJpn\nDqpXISLVoahEYWY3mNkeM+s1s9vzvB83s4eD93eYWVfOe3cE5XvM7Pqc8vvNrN/MXpjW1lIz+66Z\n7Qv+XHL+p7dwBuY44ynrmvVLqY1G+OHegYUIS0Sk5GZNFGYWBe4F3gN0AzeZWfe0arcAZ9x9A3AP\ncHewbzewFbgCuAH4fNAewJeDsuluB55w943AE8HrijMwh3socjXUxnjTuiX8cO/JhQhLRKTkiulR\nXA30uvt+d58EtgFbptXZAjwQbD8KXGdmFpRvc/cJdz8A9Abt4e4/BPJdf8lt6wHgP83hfMrm5NkJ\nGuP5H386m2s3drCnb4SXhhILEJmISGkV88zslcCRnNdHgWtmquPuU2Y2BLQH5U9N23flLMfrdPcT\nwfZLQGcRMZbdwNkJOppq57RP9rnbZyemAPjM4y9y1dqlfPCaNSWPT0SkVCp6MNvdHcj7/FAzu9XM\nesysZ2Cg/Nf7T47MfcZT1kUtdTTXxdjbpyfeiUjlKyZRHANW57xeFZTlrWNmMaAVOFXkvtP1mdmK\noK0VQH++Su5+n7tvdvfNHR0dRZxG6YxPphidLG4xwHzMjI3Lm+jtP0va9RxtEalsxSSKZ4CNZrbO\nzGrJDE5vn1ZnO3BzsH0j8GTQG9gObA1mRa0DNgJPz3K83LZuBv6xiBjLKrvG0/n2KAAuvaiF8WSK\n/QOjpQpLRGRBzJoo3H0K+BjwOLAbeMTdd5rZnWb2vqDal4B2M+sFPkEwU8nddwKPALuA7wC3uXsK\nwMz+Afh34FIzO2pmtwRtfRp4l5ntA349eF1RzoxNArCkYW5jFLkuu6iZeCzCzw5rOQ8RqWzFDGbj\n7o8Bj00r+1TOdgJ4/wz73gXclaf8phnqnwKuKyausAyOJQGKXgwwn5pohNeubOX5o0OMTU7RUFvU\nP4WISNlV9GB2pRocT1JXE6GuZu5TY3NduaaNyVSa7+7qK1FkIiKlp0RxHgbHJmmrP//LTlld7Y20\n1dfw9Z/ONr4vIhIeJYrzMDiWnNdlp6yIGVeubuNH+wboH9HNdyJSmZQozsPg+CRt8xjIznXlmjbS\nDtufO16S9kRESk0jqHOUSKZIJNO01c+/RwGwvLmOlW313P/jA68Y0Nbd2iJSKdSjmKPs1NhSXHrK\nesOaNo4PJegb1uUnEak8ShRzNBRMjZ3PPRTTvW5VGxGD5/QsbRGpQEoUc3RmfP73UEzXFI+xcXkz\nzx0Z1JIeIlJxlCjmaHBskljEaIyXdnjnyjVtDI0nOXBSS3qISGVRopijwbEkrfU1RMxK2m73ihbi\nsQjPHdblJxGpLEoUczQ4NlnSy05ZNdEI3Sta2HViWJefRKSiKFHMUeZmu9INZOda39HEeDJ17jGr\nIiKVQIliDqZSaUYmphakRwHQ1d4AwMFTGqcQkcqhRDEHQ9kZTyVY5ymfpY21NMdjHDo1tiDti4ic\nDyWKOThTguXFCzEz1i5r5KBmPolIBVGimIPBEjywaDZd7Q0Mjic5Nji+YMcQEZkLJYo5GBxPYkBL\n/cItkdXV3ghAz8HTC3YMEZG5UKKYg+HxJE3xGLHIwv21XdRaRzwW4ekDShQiUhmUKOZgPJmirnZ+\nT7WbTcSMNUsbeEY9ChGpEEoUczCRTFM/z8efFqNrWSN7+86eGxMREQmTEsUcjCdT1NUs/F/Z2qWZ\n+yl+ptVkRaQCKFHMQSKZIh5b+B7FRa11AOx9aWTBjyUiMhslijlITJXn0lNDbYyO5jh7+84u+LFE\nRGajRDEHiTJdegK4tLOZff3qUYhI+Ir61jOzG8xsj5n1mtnted6Pm9nDwfs7zKwr5707gvI9Znb9\nbG2a2XVm9lMze87MfmxmG+Z3iqWRTKVJpZ26MvQoADZ2NrGv7yzptFaSFZFwzZoozCwK3Au8B+gG\nbjKz7mnVbgHOuPsG4B7g7mDfbmArcAVwA/B5M4vO0uYXgA+5+5XAQ8An53eKpZFIpgDKlig2dTYz\nnkxx9Izu0BaRcBXTo7ga6HX3/e4+CWwDtkyrswV4INh+FLjOzCwo3+buE+5+AOgN2ivUpgMtwXYr\ncPz8Tq20Esk0QNkuPW3qbAZgb58uP4lIuIr51lsJHMl5fTQoy1vH3aeAIaC9wL6F2vwo8JiZHQU+\nDHy6mBNZaOd6FGWY9QSZS08AezVOISIhq8TB7D8C3uvuq4C/A/4yXyUzu9XMesysZ2BgYMGDSkyV\n99JTS10NK1rrNEVWREJXTKI4BqzOeb0qKMtbx8xiZC4ZnSqwb95yM+sAXu/uO4Lyh4G35gvK3e9z\n983uvrmjo6OI05ifly89lSdRQObyk6bIikjYikkUzwAbzWydmdWSGZzePq3OduDmYPtG4El396B8\nazArah2wEXi6QJtngFYz2xS09S5g9/mfXum8PJhdvk7Yps4megfOktLMJxEJ0azrZbv7lJl9DHgc\niAL3u/tOM7sT6HH37cCXgK+YWS9wmswXP0G9R4BdwBRwm7unAPK1GZT/DvA1M0uTSRy/XdIzPk/l\nnvUEsLGzmcmpNIdOjbK+o6lsxxURyVXUgxXc/THgsWlln8rZTgDvn2Hfu4C7imkzKP8G8I1i4iqn\nRDKFAbWxcvYosjOfzipRiEhoKnEwuyIlkmniNREiZmU75sblmeSwT1NkRSREShRFyizfUb7LTgCN\n8RirltSzt18D2iISHiWKIiWSqbLdQ5FrU2ezpsiKSKiUKIqUmEqXdcZT1qbOZvafPEsylS77sUVE\nQImiaGFceoLMFNlkyjl0arTsxxYRASWKooWXKDIzn/a8pHEKEQlHUdNjJTPrqZyXnh7acRjILG9u\nwNd+epSh8SQfvGZN2WIQEQH1KIri7qENZtdEIyxtrKV/OFH2Y4uIgBJFUUYnUzjlvSs71/KWOvqG\nJ0I5toiIEkURRhJJILxE0dkS59ToBFOa+SQiIVCiKMJIYgoo74KAuTqb60g7nDw7GcrxReTCpkRR\nhOHxcHsUy1viAPSNaJxCRMpPiaIIL/cowkkUHU1xIgZ9GtAWkRAoURRhODtGUcaVY3PFohHaG+P0\na0BbREKgRFGE4WyPojacHgVkLj+pRyEiYVCiKMK5WU8h3EeR1dlSx+nRyXMPUBIRKRcliiKMJKaI\nGNREy/csiukuaqnDgRe1kqyIlJkSRRGGx5PU1USxMj60aLqL2+oB2Hl8KLQYROTCpERRhJHEVGgz\nnrKWNNRQVxNh1/HhUOMQkQuPEkURRhLJ0G62yzIzVrTWs1OJQkTKTImiCMMV0KMAuLi1jhdfGiaV\n9rBDEZELiBJFEUYSyVBnPGWtaKsnkUyzf0DPphCR8lGiKEIljFEAXNyaHdDW5ScRKR8liiIMjyep\nD3mMAqCjOU5tLKKZTyJSVuF/+1W4dNoZnUwRr4AeRTRiXNrZzK4T6lGISPkUlSjM7AYz22NmvWZ2\ne57342b2cPD+DjPrynnvjqB8j5ldP1ublnGXme01s91m9vH5neL8jAV3QsdDWudpuisubmHn8WHc\nNaAtIuUx67efmUWBe4H3AN3ATWbWPa3aLcAZd98A3APcHezbDWwFrgBuAD5vZtFZ2vwIsBq4zN0v\nB7bN6wznaWwis85TbQUlisGxJMeHtO6TiJRHMd9+VwO97r7f3SfJfHFvmVZnC/BAsP0ocJ1lbmPe\nAmxz9wl3PwD0Bu0VavP3gDvdPQ3g7v3nf3rzNzqZ6VHURisjUXRf3ArAzmMapxCR8ijm228lcCTn\n9dGgLG8dd58ChoD2AvsWavMS4ANm1mNm3zazjfmCMrNbgzo9AwMDRZzG+RkNehSVcunp8hXNRCPG\n80eVKESkPCrj2++V4kDC3TcD/w+4P18ld7/P3Te7++aOjo4FC2Ys26OogPsoABpqY3SvaKHn0Omw\nQxGRC0QxieIYmTGDrFVBWd46ZhYDWoFTBfYt1OZR4OvB9jeA1xUR44IZnaysMQqAzV1LeO7IIJNT\n6bBDEZELQDHffs8AG81snZnVkhmc3j6tznbg5mD7RuBJz0zL2Q5sDWZFrQM2Ak/P0uY3gV8Ltt8O\n7D2/UyuNsYlsj6JyEsXVXUtJJNO6n0JEyiI2WwV3nzKzjwGPA1HgfnffaWZ3Aj3uvh34EvAVM+sF\nTpP54ieo9wiwC5gCbnP3FEC+NoNDfhp40Mz+CDgLfLR0pzt32R5FvEIGswGu6loCQM/BM7xhzZKQ\noxGRxW7WRAHg7o8Bj00r+1TOdgJ4/wz73gXcVUybQfkg8B+KiascKm16LMDy5jq62ht45uBpfufa\n9WGHIyKLXFGJ4kJ2bnpshSSKh3YcBmBpY5wf957kwacOYWZ88Jo1IUcmIotVZXz7VbCxySmiESMW\nCe/pdvl0tTcwNpni5NnJsEMRkUVOiWIWoxMpGmrDfQxqPl3tjQAcPDUaciQistgpUcxibHKKxtrK\nu0LX3lRLY22UQ0oUIrLAlChmMTqZoiFeGTfb5TIz1rY3cuDkqBYIFJEFpUQxi7GJyuxRAGzsbOLM\nWJJTGqcQkQWkRDGL0cnMGEUl2rS8GYA9fSMhRyIii5kSxSzGJqdojFdmj2JJYy0dTXH29StRiMjC\nUaKYxdhE5fYoADZ1NrF/YJRE8IAlEZFSU6KYxWiFznrK2tjZzFTaeWr/qbBDEZFFSoliFmMTlTnr\nKWvdskZqosYP9izcMzlE5MKmRFGAu1d8j6ImGmHdskZ+uFeJQkQWhhJFARNTadJORfcoADZ1NrP/\n5CiHT42FHYqILEJKFAVkH4NayT0KgEs7M9Nkn3yxL+RIRGQxUqIoIPsY1Eqe9QTQ3hTnko5Gnnix\nP+xQRGQRUqIoIPvQokq9jyLXr1/eyVP7T3E26AWJiJSKEkUBoxPV0aMAeOdly0mmnB9pUFtESkyJ\nooCxKupRXLV2Ca31Nbr8JCIlp0RRQDX1KGLRCO+4tIPvv9hPKq3VZEWkdJQoCjjXo6jwWU9Z113e\nyanRSZ47Mhh2KCKyiChRFJB9Xnal30eR9faNHUQjxhO7NU1WREpHiaKAsSq5jyKrtaGGq9Ys4ce9\nJ8MORUQWker4BgxJtkdRX1P5PYqHdhwGoLk+xjO7T/O3P9pPQ22MD16zJuTIRKTaqUdRwNjEFA21\nUSIRCzuUom3oaMKB/QN6lraIlEZRicLMbjCzPWbWa2a353k/bmYPB+/vMLOunPfuCMr3mNn1c2jz\nr8zs7PmdVmlknm5XXZ2uVUsaiMci9A6E+lcnIovIrInCzKLAvcB7gG7gJjPrnlbtFuCMu28A7gHu\nDvbtBrYCVwA3AJ83s+hsbZrZZmDJPM9t3jJPt6v8y065ohFj3bJGftmvRCEipVFMj+JqoNfd97v7\nJLAN2DKtzhbggWD7UeA6M7OgfJu7T7j7AaA3aG/GNoMk8hngj+d3avM3OlF9PQqASzqaODU6yZmx\nybBDEZFFoJhEsRI4kvP6aFCWt467TwFDQHuBfQu1+TFgu7ufKO4UFs7Y5BSNVXCz3XQbljcBqFch\nIiVRUb8um9nFwPuBdxRR91bgVoA1axZmZs/oZIrW+poFaXshLW+O0xyPaZxCREqimB7FMWB1zutV\nQVneOmYWA1qBUwX2nan8DcAGoNfMDgINZtabLyh3v8/dN7v75o6OjiJOY+7GJqqzR2FmXLK8iV8O\njOKu5TxEZH6KSRTPABvNbJ2Z1ZIZnN4+rc524OZg+0bgSc98Q20HtgazotYBG4GnZ2rT3f/Z3S9y\n9y537wLGggHyUIxV4aynrEs6mhidmGJP30jYoYhIlZv1W9Ddp8zsY8DjQBS43913mtmdQI+7bwe+\nBHwl+O3/NJkvfoJ6jwC7gCngNndPAeRrs/SnNz+jVTjrKeuSjkYAfrzvJJdd1BJyNCJSzYr6ddnd\nHwMem1b2qZztBJmxhXz73gXcVUybeeo0FRPfQhmr0llPAG0NtSxrivNvvSf56K+uDzscEaliujN7\nBpNTaSZT6aoco8i6pKORHQdOk0ylww5FRKqYEsUMxs+tHFudPQrITJMdm0xp2XERmRclihmce152\nFfco1i9rImKZcQoRkfOlRDGD7EOLqrlHUV8b5bWr2vg3LTsuIvOgRDGD7GNQq7lHAfArl7Tz3JFB\nzgbP1hARmSslihlkLz1V66ynrLdtWMZU2tmx/1TYoYhIlVKimMFY0KNoquJLTwBvXLuE+pooP9gz\nEHYoIlKllChmcK5HUaU33GXV1US5dtMyvre7T8t5iMh5UaKYQXaMoqHKxygAfv3yTk4MJdh5fDjs\nUESkCilRzGA4kQSoytVjp3vnZcuJGPzLrr6wQxGRKlTdF+AX0NB4kpqoUV9T3T2Kh3YcBmD10ga+\n2nOEi1rq+OA1C7Msu4gsTupRzGBwLElrfQ2ZB/VVv+4VLZwYSjCop96JyBwpUcxgeDy5KC47ZV0e\nrCC7+4TGKURkbpQoZjC0yBLFsuY4HU1xdilRiMgcKVHMYLElCoDXrmpl/8AoxwbHww5FRKqIEsUM\nBscnF12iuGrtEgAeeeZIyJGISDVRopjB0Nji61Esaahlw/ImvtpzhFRaN9+JSHGUKPJIp52RiSla\nG2rDDqXkNnct5fhQgh/u05IeIlIcJYo8RhJTuC+Om+2mu3xFM+2NtWx7+nDYoYhIlVCiyGNwPHOv\nwWJMFLFIhBuvWsUTu/vpH06EHY6IVAElijyGxhfP8h353HT1GlLufOWpQ2GHIiJVQIkij8WeKLqW\nNfLu7k6+8tShc0/yExGZiRJFHtlE0dawOBMFwK3XrmdwLMlXe46GHYqIVDgtCpjH4Nji7lFkFwpc\ns7SBz35vLxEzohHTYoEikpd6FHks9ktPWdduXMaZsSQ7jw+FHYqIVLCiEoWZ3WBme8ys18xuz/N+\n3MweDt7fYWZdOe/dEZTvMbPrZ2vTzB4Myl8ws/vNrOzf1sPjSWpjEeqqfInx2Vy2ooVlTbX8694B\n0nr6nYjMYNZEYWZR4F7gPUA3cJOZdU+rdgtwxt03APcAdwf7dgNbgSuAG4DPm1l0ljYfBC4DXgvU\nAx+d1xmeh6HxJG2LvDcBEDHj1y5dzomhBLv09DsRmUExPYqrgV533+/uk8A2YMu0OluAB4LtR4Hr\nLPMghy3ANnefcPcDQG/Q3oxtuvtjHgCeBlbN7xTnbjEuCDiT169uY1lTnCde7COtZT1EJI9iEsVK\nIHcVuaNBWd467j4FDAHtBfadtc3gktOHge/kC8rMbjWzHjPrGRgo7XIUg4twnaeZRMy47rLl9A1P\n8NgLJ8IOR0QqUCUPZn8e+KG7/yjfm+5+n7tvdvfNHR0dJT3whdSjgMzy48ub43z2e/uYSqXDDkdE\nKkwxieIYsDrn9aqgLG8dM4sBrcCpAvsWbNPM/gzoAD5RzEmU2oWWKCJmvLu7k97+s3z5JwfDDkdE\nKkwxieIZYKOZrTOzWjKD09un1dkO3Bxs3wg8GYwxbAe2BrOi1gEbyYw7zNimmX0UuB64yd1D+fV2\neDxJ6yK+2S6fy1e08M7LlvOX393LcT3YSERyzJoogjGHjwGPA7uBR9x9p5ndaWbvC6p9CWg3s14y\nvYDbg313Ao8Au8iMNdzm7qmZ2gza+iLQCfy7mT1nZp8q0bkWZSqVziwxfgH1KADMjD9/3xWk3bnz\nn3aFHY6IVJCi7sx298eAx6aVfSpnOwG8f4Z97wLuKqbNoDzUu8WHE5m1jy60RAGwemkDf3DdJu7+\nzot854UT3PCaFWGHJCIVQEt4THOh3JWdz0M7DtMUj7GyrZ4/fPg5bus7S3tTXEt7iFzgKnnWUygu\n5EQBZNZ8unoNhvHQ04dJahaUyAVPiWKawbHMQ4sW88qxs1nSWMv7N6/ixFCCf/r58bDDEZGQKVFM\nc6H3KLIuu6iFd2zqoOfQGb7ac2T2HURk0VKimGY4SBQtF3iiALju8k7WL2vkk998QWtBiVzAlCim\nUY/iZdGI8YE3raa1vobff/DZc383InJhUaKYZnAsSX1NlHhscS8xXqzmuhru/dAbOXpmnD96+Dkt\nHChyAVKimOZCW76jGG/qWsqf/cdunnyxn3u+tzfscESkzJQoplGieLWHdhwmYsbmtUv4v0/2csfX\nfxF2SCJSRkoU0yhR5GdmvO/1F7NmaQNf7TnCs4dOhx2SiJSJEsU0J4YSdLTEww6jIsWiET785rW0\n1tdwywM9/HLgbNghiUgZKFHkGJuc4vDpMS7tbA47lIrVGI/xkbd2ETXjN7/0NAdOjoYdkogsMCWK\nHPv6Mr8hb1KiKKi9Kc6Xf+tqxpMpbvzCT3j+6GDYIYnIAlKiyLGnbwSASy9SopjNa1e18ujvvoX6\n2ihb73uKrz17lMwjSERksVGiyLGvb4R4LMKapQ1hh1LxHtpxmKf2n+a/vHkty5ri/Lev/px3/sW/\n0ts/EnZoIlJiShQ59vSdZcPyJqIRCzuUqtFSV8Ot167nP1+5kpeGElz/2R/xyW/+goGRibBDE5ES\n0fMocux9aYS3XtIedhhVJ2LGm9Yt5fKLWzh2ZowHdxzmGz89xu++/RI++qvrqa/VXe4i1Uw9isDQ\nWJKXhhNs0vjEeWuKx7j0ohY+/s6NdC1r5C++u5dr/vf3+MTDz5HS0h8iVUuJIrA3uLauqbHzt6w5\nzoeuWct/vXY9rfU1fP1nx3jv537E93b1aa0okSqkS0+BPS9lEoV6FKWztr2R3337JbxwfJif/PIk\nH/37Hla21XPjVau47vLldK9oIRbV7yoilU6JIrCvb4SmeIyLW+vCDmVRMTNeu7KVy1c0s+v4MD2H\nzvC5J/bxuSf20RSPccXFLazvaGLD8ibesKaN11zcSm1MyUOkkihRBPb0jbCxswkzzXhaCLFIhNet\nauN1q9oYTiQ5eHKUAydHOTHATSTQAAAJ60lEQVSU4PmjQ4wnU0E941c2LONd3Z28q7uTzhYlbpGw\nKVEA7s6el0a4/oqLwg7lgtBSV3MuaWQNJ5IcPjXGwVOjHDw1yie/+QKf/OYLvH51G+/u7uStl7Rz\nhXobIqFQogAGRiY4M5bU0h0haqmr4TUrW3nNylbcnf6RCXafGGbXiWE+8/geAOpqIly5uo03dS3l\njWuXsH5ZIyvb6jXOIbLAikoUZnYD8DkgCvytu3962vtx4O+Bq4BTwAfc/WDw3h3ALUAK+Li7P16o\nTTNbB2wD2oFngQ+7++T8TnNm7s7/+ufdRAzevF73UFQCM6OzpY7OljrecelyRhJJDp0ao64mSs+h\n03z+B788N902GjFa6mI01Maor43SUBulsTbG6qX1rO9o4pKOJtZ3NLJmaQM1ZUgoyVSakcQUoxNT\nTEylMctcTutsqaOuRveTSHWaNVGYWRS4F3gXcBR4xsy2u/uunGq3AGfcfYOZbQXuBj5gZt3AVuAK\n4GLge2a2KdhnpjbvBu5x921m9sWg7S+U4mTz2fbMEbb//Dj//d2b6L64ZaEOI/PQHPQ2ADYsb2Ji\nKsXxwQSnRyc4PTrJ2GSKZCrN5FSaRDLF4FiSff1neaTn6Lk2zDL3ebTW1+T9aQl+6muiRCOZmwjN\njIhltiNG8Npwd06NTvLSUIL+kQQvDSXoG56gbzjBqdH8v9OYwUUtdWzsbOb1qzI9p0s6mliztEGX\n06TiFdOjuBrodff9AGa2DdgC5CaKLcD/CLYfBf7aMqPCW4Bt7j4BHDCz3qA98rVpZruBdwIfDOo8\nELS7IIli1/Fh/mz7Tn514zJ+/x0bFuIQsgDisSjrljWyblljwXrjkylOnp1g4GwmoYxPphhPpkgk\nUxw7M05v/1nGkynGJ1NMncf9HUZm2fWWuhgt9TWs72jiytWZnk08FiUWMRxIpZ3B8UlOn51kX98I\nP943QPZwESOTpOpqaK6L0VwXoyleQ7wmQm00Qk3UqIlGqIlGqI1lXkfNiESMtMPYxBRjwTmMTU4x\nNpk69zMevM70aiLEokY0YtREIjTGozTV1dAcj9EUj9EQj1IbzdSJRTLHisci1Ac9tOyfDfFMr60u\nFiUaMcwyvbpMAs30qCaDpJ1MpYME7qTdM8eOGtFIhFgkc17Zslg0U5b5CeIIYpltSR13xx0cSAfb\n6WCByux27nueUydbjmd+EciNJRvfXLk7U2lnIvjFJZFM5WynmZhKMRH8CS8fM/tvnT32uX+L6Mt/\nHzXB3032M1Gu5YaKSRQrgSM5r48C18xUx92nzGyIzKWjlcBT0/ZdGWzna7MdGHT3qTz1S+7+fztA\nW30N93zgSiJa32nRqa+NsnppA6uLWOQxmUoznkwxlfLMFwmv/JLJ/TLCoTEepbmu5rz+o05Opekb\nTnDy7AQnz04yNjl17kvkxFCCieQYqbSTcieVznzppNLpTFnayc1pNVGjNhalNmrUxjJfKtk/W+pr\nWNaUeQhX2jP7ZdsYHp+if2Ti3BfWxFSatL+6/UpgBjWRCGYE/waZGN0XPlYzMl/IZjjZRMPL2/CK\nz0u5mcHffeRNvOPS5Qt6nKodzDazW4Fbg5dnzWzP+bbV8clXFS0DTp5vexVA8Yev2s9B8Yer6Ph/\n7dOz1ylgbTGVikkUx4DVOa9XBWX56hw1sxjQSmZQu9C++cpPAW1mFgt6FfmOBYC73wfcV0T8c2Zm\nPe6+eSHaLgfFH75qPwfFH65Ki7+YUbRngI1mts7MaskMTm+fVmc7cHOwfSPwpGeeYrMd2Gpm8WA2\n00bg6ZnaDPb5ftAGQZv/eP6nJyIi8zVrjyIYc/gY8DiZqaz3u/tOM7sT6HH37cCXgK8Eg9WnyXzx\nE9R7hMzA9xRwm7unAPK1GRzyT4BtZva/gJ8FbYuISEhMj698NTO7Nbi0VZUUf/iq/RwUf7gqLX4l\nChERKUh3+oiISEFKFNOY2Q1mtsfMes3s9rDjyTKz+82s38xeyClbambfNbN9wZ9LgnIzs78KzuF5\nM3tjzj43B/X3mdnN+Y61QPGvNrPvm9kuM9tpZn9QTedgZnVm9rSZ/TyI/8+D8nVmtiOI8+FgcgbB\nBI6Hg/IdZtaV09YdQfkeM7u+HPHnHDtqZj8zs29VW/xmdtDMfmFmz5lZT1BWFZ+f4LhtZvaomb1o\nZrvN7C1VE3/mRiL9BJfgosAvgfVALfBzoDvsuILYrgXeCLyQU/Z/gNuD7duBu4Pt9wLfJnPz8JuB\nHUH5UmB/8OeSYHtJmeJfAbwx2G4G9gLd1XIOQRxNwXYNsCOI6xFga1D+ReD3gu3fB74YbG8FHg62\nu4PPVRxYF3zeomX8HH0CeAj4VvC6auIHDgLLppVVxecnOPYDwEeD7VqgrVriL8uHs1p+gLcAj+e8\nvgO4I+y4cuLp4pWJYg+wItheAewJtv8GuGl6PeAm4G9yyl9Rr8zn8o9k1vqqunMAGoCfkllN4CQQ\nm/75ITOj7y3BdiyoZ9M/U7n1yhD3KuAJMsvkfCuIp5riP8irE0VVfH7I3Ft2gGBcuNri16WnV8q3\nXMmCLSFSAp3ufiLYfgnoDLZnOo+KOL/gMsYbyPxWXjXnEFy2eQ7oB75L5rfpmZacecWyNkDusjZh\n/Rt8FvhjIB28LrRkTiXG78C/mNmzllmZAarn87MOGAD+Lrj097dm1kiVxK9EsUh45teLip/CZmZN\nwNeAP3T34dz3Kv0c3D3l7leS+c38auCykEMqmpn9BtDv7s+GHcs8vM3d3wi8B7jNzK7NfbPCPz8x\nMpeOv+DubwBGyVxqOqeS41eieKViliupJH1mtgIg+LM/KJ/pPEI9PzOrIZMkHnT3rwfFVXUOAO4+\nSGYFgbcQLDmTJ5ZzcVrxy9ospF8B3mdmB8k87+WdZJ4HUy3x4+7Hgj/7gW+QSdbV8vk5Chx19x3B\n60fJJI6qiF+J4pWKWa6kkuQunZK73Ml24DeDmRNvBoaC7u3jwLvNbEkwu+LdQdmCMzMjc5f9bnf/\ny2o7BzPrMLO2YLuezPjKbmZecmauy9osKHe/w91XuXsXmc/1k+7+oWqJ38wazaw5u03m3/0FquTz\n4+4vAUfM7NKg6DoyK1ZURfwLPgBVbT9kZhvsJXP9+U/Djicnrn8ATgBJMr+d3ELmmvETwD7ge8DS\noK6ReTDUL4FfAJtz2vltoDf4+a0yxv82Mt3q54Hngp/3Vss5AK8js6TM82S+oD4VlK8n80XZC3wV\niAfldcHr3uD99Tlt/WlwXnuA94TwWXoHL896qor4gzh/HvzszP7frJbPT3DcK4Ge4DP0TTKzlqoi\nft2ZLSIiBenSk4iIFKREISIiBSlRiIhIQUoUIiJSkBKFiIgUpEQhIiIFKVGIiEhBShQiIlLQ/wd1\nUmWpP2+P9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5uJaBMpzVjT",
        "colab_type": "code",
        "outputId": "5db8afed-09a8-4bbd-c8c4-75ff57cff145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "y = pd.get_dummies(df['SECTION'])\n",
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3\n",
              "0  0  0  0  1\n",
              "1  1  0  0  0\n",
              "2  0  0  0  1\n",
              "3  0  1  0  0\n",
              "4  0  0  0  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IOTXICt1QWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    ## Remove puncuation\n",
        "    text = text.translate(string.punctuation)\n",
        "    \n",
        "    ## Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "    \n",
        "    ## Remove stop words\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "    ## Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    ## Stemming\n",
        "    text = text.split()\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    stemmed_words = [stemmer.stem(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4xmY9O31TuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['STORY'].map(lambda x: clean_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbtBFThX16nb",
        "colab_type": "code",
        "outputId": "1620e531-0033-48ca-cca6-915815f99c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df['text'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pain huge revers fee incom unheard among privat sector lender essenti mean yes bank took grant fee structur loan deal paid account upfront book borrow turn default fee tie loan deal fell crack gill vow shift safer account practic amort fee incom rather book upfront + + + gill s move mend past way mean nasti surpris futur good news consid investor love clean imag loath uncertainti + + + but gain without pain promis strong stabl balanc sheet come sacrific well investor give hope phenomen growth promis made kapoor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWOUH7dS4jE",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq9DAbkpBmWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeGc3FSN96YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'].values, df['SECTION'].values,\n",
        "                                                    test_size = 0.2, random_state = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv54uhEs-5Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text\n",
        "\n",
        "# Vectorization parameters\n",
        "# Limit on the number of features. We use the top 20K features.\n",
        "TOP_K = 20000\n",
        "\n",
        "# Limit on the length of text sequences. Sequences longer than this\n",
        "# will be truncated.\n",
        "MAX_SEQUENCE_LENGTH = 500\n",
        "\n",
        "def sequence_vectorize(train_texts, val_texts):\n",
        "    \"\"\"Vectorizes texts as sequence vectors.\n",
        "\n",
        "    1 text = 1 sequence vector with fixed length.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val, word_index: vectorized training and validation\n",
        "            texts and word index dictionary.\n",
        "    \"\"\"\n",
        "    # Create vocabulary with training texts.\n",
        "    tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "    tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "    # Vectorize training and validation texts.\n",
        "    x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "    x_val = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "    # Get max sequence length.\n",
        "    max_length = len(max(x_train, key=len))\n",
        "    if max_length > MAX_SEQUENCE_LENGTH:\n",
        "        max_length = MAX_SEQUENCE_LENGTH\n",
        "\n",
        "    # Fix sequence length to max value. Sequences shorter than the length are\n",
        "    # padded in the beginning and sequences longer are truncated\n",
        "    # at the beginning.\n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "    x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n",
        "    return x_train, x_val, tokenizer, max_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MitAZixCPE9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, tokenizer, max_length = sequence_vectorize(X_train, X_test)\n",
        "train_labels = y_train\n",
        "val_labels = y_test \n",
        "\n",
        "units = 4\n",
        "activation = 'softmax'\n",
        "num_classes = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egzvxOhA_C1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import initializers\n",
        "from tensorflow.python.keras import regularizers\n",
        "\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from tensorflow.python.keras.layers import Embedding\n",
        "from tensorflow.python.keras.layers import SeparableConv1D\n",
        "from tensorflow.python.keras.layers import MaxPooling1D\n",
        "from tensorflow.python.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "def sepcnn_model(blocks,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 embedding_dim,\n",
        "                 dropout_rate,\n",
        "                 pool_size,\n",
        "                 input_shape,\n",
        "                 num_classes,\n",
        "                 num_features,\n",
        "                 use_pretrained_embedding=False,\n",
        "                 is_embedding_trainable=False,\n",
        "                 embedding_matrix=None):\n",
        "    \"\"\"Creates an instance of a separable CNN model.\n",
        "\n",
        "    # Arguments\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of the layers.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "        num_features: int, number of words (embedding input dimension).\n",
        "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
        "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
        "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
        "\n",
        "    # Returns\n",
        "        A sepCNN model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = units, activation\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
        "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
        "    if use_pretrained_embedding:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0],\n",
        "                            trainable=is_embedding_trainable))\n",
        "    else:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0]))\n",
        "\n",
        "    for _ in range(blocks-1):\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(MaxPooling1D(pool_size=pool_size))\n",
        "\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8C82qXpBSdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ngram_model(data,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      blocks=4,\n",
        "                      filters=64,\n",
        "                      dropout_rate=0.2,\n",
        "                      kernel_size=3,\n",
        "                      embedding_dim=200,\n",
        "                      pool_size=2):\n",
        "    \"\"\"Trains n-gram model on the given dataset.\n",
        "\n",
        "    # Arguments\n",
        "        data: tuples of training and test texts and labels.\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        blocks: int, number of blocks in the SepCNN model.\n",
        "        units: int, output dimension of Dense layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "        kernel_size: int, kernel size for sepCNN.\n",
        "        embedding_dim: int, output of embedding vector.\n",
        "        pool_size: int, size of the max pooling windows.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                         ' {unexpected_labels}. Please make sure that the '\n",
        "                         'labels in the validation set are in the same range '\n",
        "                         'as training labels.'.format(\n",
        "                             unexpected_labels=unexpected_labels))\n",
        "\n",
        "\n",
        "    # Create model instance.\n",
        "    model = sepcnn_model(blocks=blocks,\n",
        "                        filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        embedding_dim=embedding_dim,\n",
        "                        dropout_rate=dropout_rate,\n",
        "                        pool_size=pool_size,\n",
        "                        input_shape=data[0][0].shape[1:],\n",
        "                        num_classes=num_classes,\n",
        "                        num_features=max_length,\n",
        "                        use_pretrained_embedding=True,\n",
        "                        is_embedding_trainable=True)\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            train_labels,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, val_labels),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    return history['val_acc'][-1], history['val_loss'][-1], model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-ksY3gJEiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (x_train, train_labels), (x_val, val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgzrRRntR1iW",
        "colab_type": "code",
        "outputId": "5b9d54a6-eb67-45de-9e59-8be3b9d49816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETf_fqBKJFOI",
        "colab_type": "code",
        "outputId": "0cb83b5b-e9c7-4bf6-b5a4-38aa9d3df441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "train_ngram_model(data,\n",
        "                learning_rate=1e-2,\n",
        "                epochs=1000,\n",
        "                batch_size=512,\n",
        "                blocks=6,\n",
        "                filters=64,\n",
        "                dropout_rate=0.0,\n",
        "                kernel_size=5,\n",
        "                embedding_dim=50,\n",
        "                pool_size=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6102 samples, validate on 1526 samples\n",
            "Epoch 1/1000\n",
            "6102/6102 - 11s - loss: 1.3558 - acc: 0.3448 - val_loss: 1.3376 - val_acc: 0.3748\n",
            "Epoch 2/1000\n",
            "6102/6102 - 9s - loss: 1.3497 - acc: 0.3605 - val_loss: 1.3367 - val_acc: 0.3748\n",
            "Epoch 3/1000\n",
            "6102/6102 - 9s - loss: 1.3479 - acc: 0.3605 - val_loss: 1.3369 - val_acc: 0.3748\n",
            "Epoch 4/1000\n",
            "6102/6102 - 9s - loss: 1.3475 - acc: 0.3605 - val_loss: 1.3373 - val_acc: 0.3748\n",
            "Validation accuracy: 0.37483617663383484, loss: 1.3373163822906513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.37483618,\n",
              " 1.3373163822906513,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f1f0b710908>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLGHMgTK66wF",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH2Io1FSVj4q",
        "colab_type": "code",
        "outputId": "2397e596-5849-4665-fa3b-62cf91c64647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "eval_list = [l.index(max(l)) for l in model.predict(x_val).tolist()]\n",
        "print(classification_report(val_labels,eval_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       332\n",
            "           1       0.97      0.99      0.98       541\n",
            "           2       0.99      0.98      0.98       382\n",
            "           3       1.00      0.98      0.99       271\n",
            "\n",
            "    accuracy                           0.98      1526\n",
            "   macro avg       0.98      0.98      0.98      1526\n",
            "weighted avg       0.98      0.98      0.98      1526\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-ixnTvp69gz",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLpgGCcOI6S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_excel(r'Data_Test.xlsx')\n",
        "df1['text'] = df1['STORY'].map(lambda x: clean_text(x))\n",
        "x_pred = vectorizer.transform(df1['text'].values)\n",
        "x_pred = selector.transform(x_pred).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yv02Hf2Nv3m",
        "colab_type": "code",
        "outputId": "fbb1dea0-271e-4c0e-c928-ad79e47f5027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pred = model.predict(x_pred)\n",
        "pred_list = pred.tolist()\n",
        "pred_section = [l.index(max(l)) for l in pred_list]\n",
        "df1['SECTION'] = pred_section\n",
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>text</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
              "      <td>2019 see gadget like game smartphon wearabl me...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also unleashed a wave of changes in the...</td>\n",
              "      <td>also unleash wave chang mcu make sure futur lo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It can be confusing to pick the right smartpho...</td>\n",
              "      <td>confus pick right smartphon yourself segreg to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mobile application is integrated with a da...</td>\n",
              "      <td>mobil applic integr dashboard confirm regist p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We have rounded up some of the gadgets that sh...</td>\n",
              "      <td>round gadget show 2018 left indel mark on cons...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  ... SECTION\n",
              "0  2019 will see gadgets like gaming smartphones ...  ...       1\n",
              "1  It has also unleashed a wave of changes in the...  ...       2\n",
              "2  It can be confusing to pick the right smartpho...  ...       1\n",
              "3  The mobile application is integrated with a da...  ...       1\n",
              "4  We have rounded up some of the gadgets that sh...  ...       1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOSYQzQLSnmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.to_excel(r'check_pred.xlsx')\n",
        "df1['SECTION'].to_excel(r'submission.xlsx',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}